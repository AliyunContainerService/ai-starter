{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入门云原生AI - 2. 分布式mnist\n",
    "\n",
    "在深度学习世界里，算力即能力。对于网络层数较深的模型，和非常大的数据集，单机的GPU计算能力已经无法满足我们的需求。这时候我们需要分布式的深度学习解决方案。而当任务从单机发展到分布式，我们有paramter server和基于MPI的horovod这些方案解决代码层面的问题，可以帮助我们轻松将单机训练的代码变成支持分布式训练的代码。但是在运维层面，随着部署拓扑变得复杂，实例个数变多，任务数量剧增，如何高效部署，管理，调度，可重复运行分布式任务，是我们无法回避的严峻问题。\n",
    "\n",
    "而随着容器的出现和Kubernetes的诞生，带来了天然的可移植性和异构系统的调度管理能力，帮助我们更加方便快捷地运维和管理。但是正如软件工程行业的铁律「没有银弹」，Kubernetes提供了丰富而强扩展能力的编排定义模式, 但随之而来的是一定的学习成本和使用复杂度。 对于数据科学家来说，更应该专注于深度学习的工作本身，通过更高抽象的方式下发和管理查看任务。\n",
    "\n",
    "而arena的诞生就是为了解决这个问题， arena支持一系列的命令，可以通过简单的声明方式描述下发任务的拓扑信息，例如MPI任务中的Workers数量，Paramter server模式中PS和Workers的数量，GPU数量，是否开启Tensorboard 等，以及监控，日志等能力。\n",
    "接下来我们从一个分布式mnist示例开始，介绍如何通过arena提交，运维，管理一个分布式训练任务。\n",
    "在这个示例中，我们将演示：\n",
    "\n",
    "* 下载并准备数据\n",
    "* 利用Arena提交单机训练任务,并且查看训练任务状态和日志，监控GPU信息\n",
    "* 通过TensorBoard查看训练任务\n",
    "\n",
    "> 前提：请先完成文档中的[共享存储配置]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.下载TensorFlow样例源代码到${HOME}/models目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/root/models/tensorflow-sample-code'...\n",
      "remote: Enumerating objects: 242, done.\u001b[K\n",
      "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
      "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
      "remote: Total 242 (delta 93), reused 242 (delta 93)\u001b[K\n",
      "Receiving objects: 100% (242/242), 11.25 MiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (93/93), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://code.aliyun.com/xiaozhou/tensorflow-sample-code.git ${HOME}/models/tensorflow-sample-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.下载mnist数据到${HOME}/dataset/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k    0 1610k    0     0  2240k      0 --:--:-- --:--:-- --:--:-- 2242k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542    0  4542    0     0  12438      0 --:--:-- --:--:-- --:--:-- 12409\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k    0 9680k    0     0  11.2M      0 --:--:-- --:--:-- --:--:-- 11.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881    0 28881    0     0  70105      0 --:--:-- --:--:-- --:--:-- 70270\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ${HOME}/dataset/mnist && \\\n",
    "  cd ${HOME}/dataset/mnist && \\\n",
    "  curl -O https://code.aliyun.com/xiaozhou/tensorflow-sample-code/raw/master/data/t10k-images-idx3-ubyte.gz && \\\n",
    "  curl -O https://code.aliyun.com/xiaozhou/tensorflow-sample-code/raw/master/data/t10k-labels-idx1-ubyte.gz && \\\n",
    "  curl -O https://code.aliyun.com/xiaozhou/tensorflow-sample-code/raw/master/data/train-images-idx3-ubyte.gz && \\\n",
    "  curl -O https://code.aliyun.com/xiaozhou/tensorflow-sample-code/raw/master/data/train-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.检查可用GPU资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                   IPADDRESS      ROLE    GPU(Total)  GPU(Allocated)\r\n",
      "cn-zhangjiakou.i-8vb2knpxzlk449e7lugx  192.168.0.209  <none>  1           0\r\n",
      "cn-zhangjiakou.i-8vb2knpxzlk449e7lugy  192.168.0.210  <none>  1           0\r\n",
      "cn-zhangjiakou.i-8vb2knpxzlk449e7lugz  192.168.0.208  <none>  1           0\r\n",
      "cn-zhangjiakou.i-8vb7yuo831zjzijo9sdw  192.168.0.205  master  0           0\r\n",
      "cn-zhangjiakou.i-8vbezxqzueo7662i0dbq  192.168.0.204  master  0           0\r\n",
      "cn-zhangjiakou.i-8vbezxqzueo7681j4fav  192.168.0.206  master  0           0\r\n",
      "-----------------------------------------------------------------------------------------\r\n",
      "Allocated/Total GPUs In Cluster:\r\n",
      "0/3 (0%)  \r\n"
     ]
    }
   ],
   "source": [
    "! arena top node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.通过Arena提交训练任务\n",
    "这里`training-data`在配置[共享存储时]()创建.  \n",
    "`--data=training-data:/training` 将其映射到训练任务的 `/training` 目录。  \n",
    "* `/training` 目录下的子目录`/training/models/tensorflow-sample-code` 就是步骤1拷贝源代码的位置，\n",
    "* `/training` 目录下的子目录`/training/dataset/mnist` 就是步骤2下载数据的位置。\n",
    "\n",
    "和单机任务不同，TF Paramter server模式的分布式训练任务，需要指定Paramter Server和Worker的数量， 示例中我们指定为1个Paramter Server，2个Workers，两个workers分别使用1个GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/distribute-mnist-tfjob created\n",
      "configmap/distribute-mnist-tfjob labeled\n",
      "service/distribute-mnist-tensorboard created\n",
      "deployment.extensions/distribute-mnist-tensorboard created\n",
      "tfjob.kubeflow.org/distribute-mnist created\n",
      "\u001b[36mINFO\u001b[0m[0003] The Job distribute-mnist has been submitted successfully \n",
      "\u001b[36mINFO\u001b[0m[0003] You can run `arena get distribute-mnist --type tfjob` to check the job status \n"
     ]
    }
   ],
   "source": [
    "# 提交一个分布式训练任务\n",
    "!arena submit tf \\\n",
    "             --name=distribute-mnist \\\n",
    "             --ps=1 \\\n",
    "             --workers=2 \\\n",
    "             --gpus=1 \\\n",
    "             --data=training-data:/training \\\n",
    "             --image=tensorflow/tensorflow:1.11.0-gpu-py3 \\\n",
    "             \"python /training/models/tensorflow-sample-code/tfjob/docker/v1alpha2/distributed-mnist/main.py --max_steps 10000 --data_dir /training/dataset/mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 完整参数可以参考[命令行文档](https://github.com/kubeflow/arena/blob/master/docs/cli/arena_submit_tfjob.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 检查模型训练状态，当任务状态从`Pending`转为`Running`后就可以查看日志和GPU使用率了。这里`-e`为了方便检查任务`Pending`的原因。\n",
    "我们可以通过get命令查看到这个任务的容器分布，示例中有1个ps容器和2个workers容器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS: RUNNING\n",
      "NAMESPACE: default\n",
      "TRAINING DURATION: 2m\n",
      "\n",
      "NAME              STATUS   TRAINER  AGE  INSTANCE                   NODE\n",
      "distribute-mnist  RUNNING  TFJOB    2m   distribute-mnist-ps-0      192.168.0.208\n",
      "distribute-mnist  RUNNING  TFJOB    2m   distribute-mnist-worker-0  192.168.0.210\n",
      "distribute-mnist  RUNNING  TFJOB    2m   distribute-mnist-worker-1  192.168.0.209\n",
      "\n",
      "Your tensorboard will be available on:\n",
      "192.168.0.206:32032   \n",
      "\n",
      "Events: \n",
      "No events for pending pod\n"
     ]
    }
   ],
   "source": [
    "! arena get distribute-mnist -e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.实时检查日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-22T13:44:03.262560773Z Adding run metadata for 1999\n",
      "2019-02-22T13:44:03.262563328Z Accuracy at step 2000: 0.9801\n",
      "2019-02-22T13:44:03.262565685Z Accuracy at step 2010: 0.9772\n",
      "2019-02-22T13:44:03.262568164Z Accuracy at step 2020: 0.9769\n",
      "2019-02-22T13:44:03.262570601Z Accuracy at step 2030: 0.9777\n",
      "2019-02-22T13:44:03.262573095Z Accuracy at step 2040: 0.9803\n",
      "2019-02-22T13:44:03.262575451Z Accuracy at step 2050: 0.9785\n",
      "2019-02-22T13:44:03.26257794Z Accuracy at step 2060: 0.9775\n",
      "2019-02-22T13:44:03.2625803Z Accuracy at step 2070: 0.978\n",
      "2019-02-22T13:44:03.262582851Z Accuracy at step 2080: 0.978\n",
      "2019-02-22T13:44:03.26258519Z Accuracy at step 2090: 0.9789\n",
      "2019-02-22T13:44:03.262587707Z Adding run metadata for 2099\n",
      "2019-02-22T13:44:03.262590064Z Accuracy at step 2100: 0.9781\n",
      "2019-02-22T13:44:03.262592509Z Accuracy at step 2110: 0.9778\n",
      "2019-02-22T13:44:03.262594844Z Accuracy at step 2120: 0.977\n",
      "2019-02-22T13:44:03.262597213Z Accuracy at step 2130: 0.9782\n",
      "2019-02-22T13:44:03.26259955Z Accuracy at step 2140: 0.9769\n",
      "2019-02-22T13:44:03.26260194Z Accuracy at step 2150: 0.9783\n",
      "2019-02-22T13:44:03.262604267Z Accuracy at step 2160: 0.9773\n",
      "2019-02-22T13:44:03.262606612Z Accuracy at step 2170: 0.9769\n",
      "2019-02-22T13:44:03.262608985Z Accuracy at step 2180: 0.9779\n",
      "2019-02-22T13:44:03.262611325Z Accuracy at step 2190: 0.9789\n",
      "2019-02-22T13:44:03.262613651Z Adding run metadata for 2199\n",
      "2019-02-22T13:44:03.262616022Z Accuracy at step 2200: 0.978\n",
      "2019-02-22T13:44:03.262618361Z Accuracy at step 2210: 0.9807\n",
      "2019-02-22T13:44:03.262620705Z Accuracy at step 2220: 0.9805\n",
      "2019-02-22T13:44:03.262623217Z Accuracy at step 2230: 0.9778\n",
      "2019-02-22T13:44:03.26262574Z Accuracy at step 2240: 0.9798\n",
      "2019-02-22T13:44:03.262628101Z Accuracy at step 2250: 0.9801\n",
      "2019-02-22T13:44:03.262630581Z Accuracy at step 2260: 0.979\n",
      "2019-02-22T13:44:03.262633051Z Accuracy at step 2270: 0.9797\n",
      "2019-02-22T13:44:03.262635388Z Accuracy at step 2280: 0.9787\n",
      "2019-02-22T13:44:03.262637892Z Accuracy at step 2290: 0.9779\n",
      "2019-02-22T13:44:03.262640264Z Adding run metadata for 2299\n",
      "2019-02-22T13:44:03.262642763Z Accuracy at step 2300: 0.9799\n",
      "2019-02-22T13:44:03.262648375Z Accuracy at step 2310: 0.9786\n",
      "2019-02-22T13:44:03.262650862Z Accuracy at step 2320: 0.9793\n",
      "2019-02-22T13:44:03.26265334Z Accuracy at step 2330: 0.9796\n",
      "2019-02-22T13:44:03.262655722Z Accuracy at step 2340: 0.9799\n",
      "2019-02-22T13:44:03.262658168Z Accuracy at step 2350: 0.9804\n",
      "2019-02-22T13:44:03.262660588Z Accuracy at step 2360: 0.9809\n",
      "2019-02-22T13:44:03.262662936Z Accuracy at step 2370: 0.9806\n",
      "2019-02-22T13:44:03.262665416Z Accuracy at step 2380: 0.9796\n",
      "2019-02-22T13:44:03.262667908Z Accuracy at step 2390: 0.9803\n",
      "2019-02-22T13:44:03.26267025Z Adding run metadata for 2399\n",
      "2019-02-22T13:44:03.262672775Z Accuracy at step 2400: 0.9797\n",
      "2019-02-22T13:44:03.262675114Z Accuracy at step 2410: 0.9806\n",
      "2019-02-22T13:44:03.262677449Z Accuracy at step 2420: 0.9803\n",
      "2019-02-22T13:44:03.26267981Z Accuracy at step 2430: 0.9791\n",
      "2019-02-22T13:44:03.262682169Z Accuracy at step 2440: 0.981\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# get the job logs\n",
    "! arena logs -f --tail=50 distribute-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.查看实时训练的GPU使用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              GPU(Requests)  GPU(Allocated)  STATUS   TRAINER  AGE  NODE\r\n",
      "distribute-mnist  2              2               RUNNING  tfjob    3m   192.168.0.210\r\n",
      "\r\n",
      "\r\n",
      "Total Allocated GPUs of Training Job:\r\n",
      "2   \r\n",
      "\r\n",
      "Total Requested GPUs of Training Job:\r\n",
      "2   \r\n"
     ]
    }
   ],
   "source": [
    "! arena top job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.通过TensorBoard查看训练趋势。您可以使用 `192.168.1.117:30670` 访问 Tensorboard。如果您通过笔记本电脑无法直接访问 Tensorboard，可以考虑使用 `sshuttle`。例如：`sshuttle -r root@41.82.59.51 192.168.0.0/16`。其中`41.82.59.51`为集群内某个节点的外网IP，且该外网IP可以通过ssh访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS: RUNNING\r\n",
      "NAMESPACE: default\r\n",
      "TRAINING DURATION: 1m\r\n",
      "\r\n",
      "NAME              STATUS     TRAINER  AGE  INSTANCE                   NODE\r\n",
      "distribute-mnist  RUNNING    TFJOB    1m   distribute-mnist-ps-0      192.168.0.208\r\n",
      "distribute-mnist  RUNNING    TFJOB    1m   distribute-mnist-worker-0  192.168.0.210\r\n",
      "distribute-mnist  SUCCEEDED  TFJOB    1m   distribute-mnist-worker-1  N/A\r\n",
      "\r\n",
      "Your tensorboard will be available on:\r\n",
      "192.168.0.206:32684   \r\n"
     ]
    }
   ],
   "source": [
    "! arena get distribute-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2-tensorboard.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.删除已经完成的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service \"distribute-mnist-tensorboard\" deleted\n",
      "deployment.extensions \"distribute-mnist-tensorboard\" deleted\n",
      "tfjob.kubeflow.org \"distribute-mnist\" deleted\n",
      "configmap \"distribute-mnist-tfjob\" deleted\n",
      "\u001b[36mINFO\u001b[0m[0004] The Job distribute-mnist has been deleted successfully \n"
     ]
    }
   ],
   "source": [
    "! arena delete distribute-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恭喜！您已经使用 `arena` 成功运行了训练作业，而且还能轻松检查 Tensorboard。\n",
    "\n",
    "总结，希望您通过本次演示了解：\n",
    "1. 如何准备代码和数据，并将其放入数据卷中\n",
    "2. 如何在训练任务中引用数据卷，并且使用其中的代码和数据\n",
    "3. 如何利用arena管理您的分布式训练任务。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
